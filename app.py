from flask import Flask, request, jsonify, send_from_directory
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
import numpy as np
import os
import re

app = Flask(__name__)

# Ø§Ø³ØªØ®Ø¯Ø§Ù… EfficientNet Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† MobileNet Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¯Ù‚Ø© Ø£ÙØ¶Ù„
model = EfficientNetB0(weights="imagenet")
print("ğŸ¤– ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")

# Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ù„Ù„Ø£ØµÙ†Ø§Ù Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
ARABIC_TRANSLATIONS = {
    # Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª
    'egyptian_cat': 'Ù‚Ø·Ø© Ù…ØµØ±ÙŠØ©',
    'tabby': 'Ù‚Ø·Ø© Ù…Ø®Ø·Ø·Ø©',
    'tiger_cat': 'Ù‚Ø·Ø© Ù†Ù…Ø±ÙŠØ©',
    'persian_cat': 'Ù‚Ø·Ø© ÙØ§Ø±Ø³ÙŠØ©',
    'siamese_cat': 'Ù‚Ø·Ø© Ø³ÙŠØ§Ù…ÙŠØ©',
    'cat': 'Ù‚Ø·Ø©',
    'kitten': 'Ù‚Ø·Ø© ØµØºÙŠØ±Ø©',
    
    'golden_retriever': 'ÙƒÙ„Ø¨ Ø¬ÙˆÙ„Ø¯Ù† Ø±ÙŠØªØ±ÙŠÙØ±',
    'german_shepherd': 'ÙƒÙ„Ø¨ Ø§Ù„Ø±Ø§Ø¹ÙŠ Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠ',
    'beagle': 'ÙƒÙ„Ø¨ Ø¨ÙŠØ¬Ù„',
    'bulldog': 'ÙƒÙ„Ø¨ Ø¨ÙˆÙ„Ø¯ÙˆØ¬',
    'poodle': 'ÙƒÙ„Ø¨ Ø¨ÙˆØ¯Ù„',
    'chihuahua': 'ÙƒÙ„Ø¨ ØªØ´ÙŠÙ‡ÙˆØ§Ù‡ÙˆØ§',
    'labrador_retriever': 'ÙƒÙ„Ø¨ Ù„Ø§Ø¨Ø±Ø§Ø¯ÙˆØ±',
    'dog': 'ÙƒÙ„Ø¨',
    'puppy': 'Ø¬Ø±Ùˆ',
    
    'horse': 'Ø­ØµØ§Ù†',
    'cow': 'Ø¨Ù‚Ø±Ø©',
    'sheep': 'Ø®Ø±ÙˆÙ',
    'pig': 'Ø®Ù†Ø²ÙŠØ±',
    'goat': 'Ù…Ø§Ø¹Ø²',
    'chicken': 'Ø¯Ø¬Ø§Ø¬Ø©',
    'duck': 'Ø¨Ø·Ø©',
    'goose': 'Ø¥ÙˆØ²Ø©',
    'turkey': 'Ø¯ÙŠÙƒ Ø±ÙˆÙ…ÙŠ',
    
    'elephant': 'ÙÙŠÙ„',
    'lion': 'Ø£Ø³Ø¯',
    'tiger': 'Ù†Ù…Ø±',
    'bear': 'Ø¯Ø¨',
    'zebra': 'Ø­Ù…Ø§Ø± ÙˆØ­Ø´ÙŠ',
    'giraffe': 'Ø²Ø±Ø§ÙØ©',
    'monkey': 'Ù‚Ø±Ø¯',
    'snake': 'Ø«Ø¹Ø¨Ø§Ù†',
    'bird': 'Ø·Ø§Ø¦Ø±',
    'eagle': 'Ù†Ø³Ø±',
    'owl': 'Ø¨ÙˆÙ…Ø©',
    'parrot': 'Ø¨Ø¨ØºØ§Ø¡',
    'fish': 'Ø³Ù…ÙƒØ©',
    'shark': 'Ù‚Ø±Ø´',
    'whale': 'Ø­ÙˆØª',
    'dolphin': 'Ø¯ÙˆÙ„ÙÙŠÙ†',
    'turtle': 'Ø³Ù„Ø­ÙØ§Ø©',
    'frog': 'Ø¶ÙØ¯Ø¹',
    'spider': 'Ø¹Ù†ÙƒØ¨ÙˆØª',
    'butterfly': 'ÙØ±Ø§Ø´Ø©',
    'bee': 'Ù†Ø­Ù„Ø©',
    'ant': 'Ù†Ù…Ù„Ø©',
    
    # Ø§Ù„Ø£Ø´Ø®Ø§Øµ
    'person': 'Ø´Ø®Øµ',
    'man': 'Ø±Ø¬Ù„',
    'woman': 'Ø§Ù…Ø±Ø£Ø©',
    'child': 'Ø·ÙÙ„',
    'baby': 'Ø±Ø¶ÙŠØ¹',
    'boy': 'ÙˆÙ„Ø¯',
    'girl': 'Ø¨Ù†Øª',
    'face': 'ÙˆØ¬Ù‡',
    
    # Ø§Ù„Ù…Ø¨Ø§Ù†ÙŠ ÙˆØ§Ù„Ø£Ù…Ø§ÙƒÙ†
    'house': 'Ø¨ÙŠØª',
    'building': 'Ù…Ø¨Ù†Ù‰',
    'church': 'ÙƒÙ†ÙŠØ³Ø©',
    'mosque': 'Ù…Ø³Ø¬Ø¯',
    'castle': 'Ù‚Ù„Ø¹Ø©',
    'tower': 'Ø¨Ø±Ø¬',
    'bridge': 'Ø¬Ø³Ø±',
    'road': 'Ø·Ø±ÙŠÙ‚',
    'street': 'Ø´Ø§Ø±Ø¹',
    'park': 'Ø­Ø¯ÙŠÙ‚Ø©',
    'garden': 'Ø¨Ø³ØªØ§Ù†',
    'beach': 'Ø´Ø§Ø·Ø¦',
    'mountain': 'Ø¬Ø¨Ù„',
    'forest': 'ØºØ§Ø¨Ø©',
    'desert': 'ØµØ­Ø±Ø§Ø¡',
    'lake': 'Ø¨Ø­ÙŠØ±Ø©',
    'river': 'Ù†Ù‡Ø±',
    'sea': 'Ø¨Ø­Ø±',
    'ocean': 'Ù…Ø­ÙŠØ·',
    'sky': 'Ø³Ù…Ø§Ø¡',
    'cloud': 'Ø³Ø­Ø§Ø¨Ø©',
    'sun': 'Ø´Ù…Ø³',
    'moon': 'Ù‚Ù…Ø±',
    'star': 'Ù†Ø¬Ù…Ø©',
    
    # Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª
    'car': 'Ø³ÙŠØ§Ø±Ø©',
    'truck': 'Ø´Ø§Ø­Ù†Ø©',
    'bus': 'Ø­Ø§ÙÙ„Ø©',
    'motorcycle': 'Ø¯Ø±Ø§Ø¬Ø© Ù†Ø§Ø±ÙŠØ©',
    'bicycle': 'Ø¯Ø±Ø§Ø¬Ø© Ù‡ÙˆØ§Ø¦ÙŠØ©',
    'airplane': 'Ø·Ø§Ø¦Ø±Ø©',
    'helicopter': 'Ù‡Ù„ÙŠÙƒÙˆØ¨ØªØ±',
    'boat': 'Ù‚Ø§Ø±Ø¨',
    'ship': 'Ø³ÙÙŠÙ†Ø©',
    'train': 'Ù‚Ø·Ø§Ø±',
    
    # Ø§Ù„Ø·Ø¹Ø§Ù…
    'apple': 'ØªÙØ§Ø­Ø©',
    'banana': 'Ù…ÙˆØ²Ø©',
    'orange': 'Ø¨Ø±ØªÙ‚Ø§Ù„Ø©',
    'strawberry': 'ÙØ±Ø§ÙˆÙ„Ø©',
    'grape': 'Ø¹Ù†Ø¨',
    'pizza': 'Ø¨ÙŠØªØ²Ø§',
    'burger': 'Ø¨Ø±Ø¬Ø±',
    'bread': 'Ø®Ø¨Ø²',
    'cake': 'ÙƒÙŠÙƒØ©',
    'coffee': 'Ù‚Ù‡ÙˆØ©',
    'tea': 'Ø´Ø§ÙŠ',
    'water': 'Ù…Ø§Ø¡',
    'milk': 'Ø­Ù„ÙŠØ¨',
    'cheese': 'Ø¬Ø¨Ù†Ø©',
    'meat': 'Ù„Ø­Ù…',
    'chicken_meat': 'Ù„Ø­Ù… Ø¯Ø¬Ø§Ø¬',
    'fish_food': 'Ø³Ù…Ùƒ (Ø·Ø¹Ø§Ù…)',
    'rice': 'Ø£Ø±Ø²',
    'pasta': 'Ù…ÙƒØ±ÙˆÙ†Ø©',
    'salad': 'Ø³Ù„Ø·Ø©',
    'soup': 'Ø´ÙˆØ±Ø¨Ø©',
    'ice_cream': 'Ø¢ÙŠØ³ ÙƒØ±ÙŠÙ…',
    'chocolate': 'Ø´ÙˆÙƒÙˆÙ„Ø§ØªØ©',
    'candy': 'Ø­Ù„ÙˆÙ‰',
    
    # Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙˆØ§Ù„Ø£Ø´ÙŠØ§Ø¡
    'phone': 'Ù‡Ø§ØªÙ',
    'computer': 'ÙƒÙ…Ø¨ÙŠÙˆØªØ±',
    'laptop': 'Ù„Ø§Ø¨ØªÙˆØ¨',
    'television': 'ØªÙ„ÙØ²ÙŠÙˆÙ†',
    'camera': 'ÙƒØ§Ù…ÙŠØ±Ø§',
    'book': 'ÙƒØªØ§Ø¨',
    'pen': 'Ù‚Ù„Ù…',
    'pencil': 'Ù‚Ù„Ù… Ø±ØµØ§Øµ',
    'paper': 'ÙˆØ±Ù‚',
    'bag': 'Ø­Ù‚ÙŠØ¨Ø©',
    'chair': 'ÙƒØ±Ø³ÙŠ',
    'table': 'Ø·Ø§ÙˆÙ„Ø©',
    'bed': 'Ø³Ø±ÙŠØ±',
    'door': 'Ø¨Ø§Ø¨',
    'window': 'Ù†Ø§ÙØ°Ø©',
    'mirror': 'Ù…Ø±Ø¢Ø©',
    'clock': 'Ø³Ø§Ø¹Ø©',
    'watch': 'Ø³Ø§Ø¹Ø© ÙŠØ¯',
    'key': 'Ù…ÙØªØ§Ø­',
    'lamp': 'Ù…ØµØ¨Ø§Ø­',
    'flower': 'Ø²Ù‡Ø±Ø©',
    'tree': 'Ø´Ø¬Ø±Ø©',
    'grass': 'Ø¹Ø´Ø¨',
    'leaf': 'ÙˆØ±Ù‚Ø© Ø´Ø¬Ø±',
    'stone': 'Ø­Ø¬Ø±',
    'rock': 'ØµØ®Ø±Ø©',
    'sand': 'Ø±Ù…Ù„',
    'snow': 'Ø«Ù„Ø¬',
    'ice': 'Ø¬Ù„ÙŠØ¯',
    'fire': 'Ù†Ø§Ø±',
    'smoke': 'Ø¯Ø®Ø§Ù†',
    
    # Ø§Ù„Ø±ÙŠØ§Ø¶Ø©
    'football': 'ÙƒØ±Ø© Ù‚Ø¯Ù…',
    'basketball': 'ÙƒØ±Ø© Ø³Ù„Ø©',
    'tennis_ball': 'ÙƒØ±Ø© ØªÙ†Ø³',
    'golf_ball': 'ÙƒØ±Ø© Ø¬ÙˆÙ„Ù',
    'baseball': 'Ø¨ÙŠØ³Ø¨ÙˆÙ„',
    'volleyball': 'ÙƒØ±Ø© Ø·Ø§Ø¦Ø±Ø©',
    
    # Ø§Ù„Ù…Ù„Ø§Ø¨Ø³
    'shirt': 'Ù‚Ù…ÙŠØµ',
    'pants': 'Ø¨Ù†Ø·Ø§Ù„',
    'dress': 'ÙØ³ØªØ§Ù†',
    'shoes': 'Ø£Ø­Ø°ÙŠØ©',
    'hat': 'Ù‚Ø¨Ø¹Ø©',
    'jacket': 'Ø¬Ø§ÙƒÙŠØª',
    'tie': 'Ø±Ø¨Ø·Ø© Ø¹Ù†Ù‚',
    'socks': 'Ø¬ÙˆØ§Ø±Ø¨',
    'gloves': 'Ù‚ÙØ§Ø²Ø§Øª',
    'belt': 'Ø­Ø²Ø§Ù…',
}

def clean_label(label):
    """ØªÙ†Ø¸ÙŠÙ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ³Ù…ÙŠØ©"""
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø®Ø§ØµØ©
    cleaned = re.sub(r'[0-9_-]', ' ', label.lower())
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    cleaned = ' '.join(cleaned.split())
    return cleaned.strip()

def get_arabic_translation(english_label):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªØ³Ù…ÙŠØ©
    cleaned_label = clean_label(english_label)
    
    # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
    if cleaned_label in ARABIC_TRANSLATIONS:
        return ARABIC_TRANSLATIONS[cleaned_label]
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
    for key, value in ARABIC_TRANSLATIONS.items():
        if key in cleaned_label or cleaned_label in key:
            return value
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙØ±Ø¯ÙŠØ©
    words = cleaned_label.split()
    for word in words:
        if word in ARABIC_TRANSLATIONS:
            return ARABIC_TRANSLATIONS[word]
    
    # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªØ±Ø¬Ù…Ø©ØŒ Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ Ù…Ø­Ø³Ù†
    return cleaned_label.title()

@app.route("/")
def index():
    return send_from_directory(".", "index.html")

@app.route("/predict", methods=["POST"])
def predict():
    if "file" not in request.files:
        return jsonify({"error": "Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ø£ÙŠ Ù…Ù„Ù"})
    
    file = request.files["file"]
    if file.filename == "":
        return jsonify({"error": "Ù„Ù… ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø£ÙŠ Ù…Ù„Ù"})

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù
    allowed_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}
    file_extension = os.path.splitext(file.filename)[1].lower()
    
    if file_extension not in allowed_extensions:
        return jsonify({"error": "Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…. ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØµÙˆØ± Ø¨ØµÙŠØºØ© JPG, PNG, GIF"})

    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ uploads Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
    upload_folder = os.path.join(os.getcwd(), "uploads")
    os.makedirs(upload_folder, exist_ok=True)

    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø¨Ø£Ø³Ù… Ø¢Ù…Ù†
    import time
    safe_filename = f"{int(time.time())}_{file.filename}"
    filepath = os.path.join(upload_folder, safe_filename)
    file.save(filepath)

    print(f"ğŸ“ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ: {filepath}")

    try:
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
        img = image.load_img(filepath, target_size=(224, 224))
        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)

        # ØªÙˆÙ‚Ø¹ Ø§Ù„ØªØµÙ†ÙŠÙ - Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ 3 Ù†ØªØ§Ø¦Ø¬
        preds = model.predict(x, verbose=0)
        decoded_predictions = decode_predictions(preds, top=3)[0]
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©
        best_prediction = decoded_predictions[0]
        class_id, english_label, confidence = best_prediction
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        arabic_label = get_arabic_translation(english_label)
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
        clean_english_label = clean_label(english_label).title()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ù…Ø¹ Ø§Ù„ØªØ±Ø¬Ù…Ø§Øª
        all_predictions = []
        for pred in decoded_predictions:
            pred_english = clean_label(pred[1]).title()
            pred_arabic = get_arabic_translation(pred[1])
            all_predictions.append({
                "english": pred_english,
                "arabic": pred_arabic,
                "confidence": float(pred[2])
            })
        
        # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        try:
            os.remove(filepath)
        except:
            pass
        
        return jsonify({
            "english_label": clean_english_label,
            "arabic_label": arabic_label,
            "confidence": float(confidence),
            "all_predictions": all_predictions,
            "success": True
        })
        
    except Exception as e:
        # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
        try:
            os.remove(filepath)
        except:
            pass
            
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}")
        return jsonify({
            "error": f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}",
            "success": False
        })

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø®Ø§Ø¯Ù… ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ±...")
    print("ğŸ“± Ø§Ù„Ø±Ø§Ø¨Ø·: http://0.0.0.0:{}".format(port))
    app.run(debug=False, host='0.0.0.0', port=port)